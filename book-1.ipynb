{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv').fillna('undef')\n",
    "test = pd.read_csv('test.csv').fillna('undef').drop('id', axis=1)\n",
    "X = train.drop(['id','target'], axis =1)\n",
    "y = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_second_tag(df):\n",
    "    col1 = []\n",
    "    col2 = []\n",
    "    for x in df['keyword']:\n",
    "        try:\n",
    "            smth = x.split(\"%20\")\n",
    "            col2.append(smth[1])\n",
    "            col1.append(smth[0])\n",
    "        except:\n",
    "            col2.append(\"undef\")\n",
    "            col1.append(x)\n",
    "    df.drop('keyword', axis=1, inplace = True)\n",
    "    df['keyword_one'] = col1\n",
    "    df['keyword_two'] = col2\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = separate_second_tag(X)\n",
    "test = separate_second_tag(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "mispell_dict = {\"aren't\" : \"are not\",\n",
    "\"can't\" : \"cannot\",\n",
    "\"couldn't\" : \"could not\",\n",
    "\"couldnt\" : \"could not\",\n",
    "\"didn't\" : \"did not\",\n",
    "\"doesn't\" : \"does not\",\n",
    "\"doesnt\" : \"does not\",\n",
    "\"don't\" : \"do not\",\n",
    "\"hadn't\" : \"had not\",\n",
    "\"hasn't\" : \"has not\",\n",
    "\"haven't\" : \"have not\",\n",
    "\"havent\" : \"have not\",\n",
    "\"he'd\" : \"he would\",\n",
    "\"he'll\" : \"he will\",\n",
    "\"he's\" : \"he is\",\n",
    "\"i'd\" : \"I would\",\n",
    "\"i'd\" : \"I had\",\n",
    "\"i'll\" : \"I will\",\n",
    "\"i'm\" : \"I am\",\n",
    "\"isn't\" : \"is not\",\n",
    "\"it's\" : \"it is\",\n",
    "\"it'll\":\"it will\",\n",
    "\"i've\" : \"I have\",\n",
    "\"let's\" : \"let us\",\n",
    "\"mightn't\" : \"might not\",\n",
    "\"mustn't\" : \"must not\",\n",
    "\"shan't\" : \"shall not\",\n",
    "\"she'd\" : \"she would\",\n",
    "\"she'll\" : \"she will\",\n",
    "\"she's\" : \"she is\",\n",
    "\"shouldn't\" : \"should not\",\n",
    "\"shouldnt\" : \"should not\",\n",
    "\"that's\" : \"that is\",\n",
    "\"thats\" : \"that is\",\n",
    "\"there's\" : \"there is\",\n",
    "\"theres\" : \"there is\",\n",
    "\"they'd\" : \"they would\",\n",
    "\"they'll\" : \"they will\",\n",
    "\"they're\" : \"they are\",\n",
    "\"theyre\":  \"they are\",\n",
    "\"they've\" : \"they have\",\n",
    "\"we'd\" : \"we would\",\n",
    "\"we're\" : \"we are\",\n",
    "\"weren't\" : \"were not\",\n",
    "\"we've\" : \"we have\",\n",
    "\"what'll\" : \"what will\",\n",
    "\"what're\" : \"what are\",\n",
    "\"what's\" : \"what is\",\n",
    "\"what've\" : \"what have\",\n",
    "\"where's\" : \"where is\",\n",
    "\"who'd\" : \"who would\",\n",
    "\"who'll\" : \"who will\",\n",
    "\"who're\" : \"who are\",\n",
    "\"who's\" : \"who is\",\n",
    "\"who've\" : \"who have\",\n",
    "\"won't\" : \"will not\",\n",
    "\"wouldn't\" : \"would not\",\n",
    "\"you'd\" : \"you would\",\n",
    "\"you'll\" : \"you will\",\n",
    "\"you're\" : \"you are\",\n",
    "\"you've\" : \"you have\",\n",
    "\"'re\": \" are\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'll\":\" will\",\n",
    "\"didn't\": \"did not\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_typical_misspell(text):\n",
    "    mispellings_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
    "    def replace(match):\n",
    "        return mispell_dict[match.group(0)]\n",
    "    return mispellings_re.sub(replace, text)\n",
    "\n",
    "def text_cleaning(ln):\n",
    "    corpus = []\n",
    "    wordnet = WordNetLemmatizer()\n",
    "    for text in ln:\n",
    "        text = replace_typical_misspell(text)\n",
    "        text = ' '.join(text.split('.'))\n",
    "        text = re.sub(r'\\s+', ' ', re.sub('[^A-Za-z0-9]', ' ', text.strip().lower())).strip()\n",
    "        text = re.sub(r'\\W+', ' ', text.strip().lower()).strip()\n",
    "        text = [wordnet.lemmatize(word) for word in text.split(\" \") if word not in set(stopwords.words('english'))]\n",
    "        text = ' '.join(text)\n",
    "        corpus.append(text)\n",
    "        pass\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['text'] = text_cleaning(list(X['text']))\n",
    "test['text'] = text_cleaning(list(test['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['location'] = text_cleaning(list(X['location']))\n",
    "test['location'] = text_cleaning(list(test['location']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "def location_detection(ln):\n",
    "    bins = []\n",
    "    for text in ln:\n",
    "        doc = nlp(text)\n",
    "        entities = []\n",
    "        for ent in doc.ents:\n",
    "            entities.append(ent)\n",
    "        if len(entities)>0:\n",
    "            bins.append(1)\n",
    "        else:\n",
    "            bins.append(0)\n",
    "    return bins\n",
    "\n",
    "X['location_legit'] = location_detection(X['location'])\n",
    "test['location_legit'] = location_detection(test['location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>keyword_one</th>\n",
       "      <th>keyword_two</th>\n",
       "      <th>location_legit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>undef</td>\n",
       "      <td>deed reason earthquake may allah forgive u</td>\n",
       "      <td>undef</td>\n",
       "      <td>undef</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>undef</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>undef</td>\n",
       "      <td>undef</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>undef</td>\n",
       "      <td>resident asked shelter place notified officer ...</td>\n",
       "      <td>undef</td>\n",
       "      <td>undef</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>undef</td>\n",
       "      <td>13 000 people receive wildfire evacuation orde...</td>\n",
       "      <td>undef</td>\n",
       "      <td>undef</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>undef</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfire pour...</td>\n",
       "      <td>undef</td>\n",
       "      <td>undef</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location                                               text keyword_one  \\\n",
       "0    undef         deed reason earthquake may allah forgive u       undef   \n",
       "1    undef              forest fire near la ronge sask canada       undef   \n",
       "2    undef  resident asked shelter place notified officer ...       undef   \n",
       "3    undef  13 000 people receive wildfire evacuation orde...       undef   \n",
       "4    undef  got sent photo ruby alaska smoke wildfire pour...       undef   \n",
       "\n",
       "  keyword_two  location_legit  \n",
       "0       undef               0  \n",
       "1       undef               0  \n",
       "2       undef               0  \n",
       "3       undef               0  \n",
       "4       undef               0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
